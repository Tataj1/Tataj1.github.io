---
layout: post
title: "Day 11 â€“ Deep Dive into Exploratory Data Analysis with Pandas"
date: 2025-06-10
author: Tahia Tajnim
permalink: /day11.html
tags: ["Exploratory Data Analysis", "Pandas", "Flight Delay Dataset", "Python Practice", "CEAMLS Summer AI"]  

what_i_learned: |
  Today I deepened my understanding of building end-to-end machine learning pipelines using Python and XGBoost. I reviewed several educational videos that covered essential concepts like Exploratory Data Analysis (EDA), data cleaning, model training, and evaluation. I learned how EDA helps detect missing values, outliers, and data imbalances before model training. I also studied the importance of splitting data into training and testing sets to avoid overfitting and ensure that the model generalizes well. I reviewed how XGBoost works using sequential decision trees and why it's popular due to speed, accuracy, and built-in regularization. Additionally, I learned about hyperparameter tuning techniques such as grid search and random search to optimize model performance. I created a Kahoot-style quiz for self-assessment and reviewed key XGBoost hyperparameters like learning_rate, max_depth, and n_estimators. On the coding side, I troubleshooted a NameError in a Jupyter notebook where a DataFrame variable was incorrectly referenced as df_encode instead of df or df_encoded. This reinforced the importance of tracking variable names when working with transformed datasets.
  
blockers: |  
  Initially, I found it challenging to fully understand some of the more complex dataset manipulations like multi-level grouping and chaining multiple pandas methods. However, pausing the videos and practicing each step in Colab helped me overcome those difficulties.
  
reflection: |
  This was a very productive workday. Watching structured tutorials and seeing real-life applications of pandas made me realize the power of Python in handling and understanding data. Practicing along with the instructors helped reinforce my skills. It also connected well to our flight delay prediction project, giving me practical tools I can apply soon. I feel more equipped to work with datasets and excited to dive deeper into modeling next.
---


