---
layout: post
title: "Day 22 –  Evaluating and Improving Traditional ML Models"

date: 2025-06-25
author: Tahia Tajnim
permalink: /day22.html
tags: ["flight delay prediction", "machine learning", "model evaluation", "RMSE", "MAE", "accuracy"]   

what_i_learned: |
  Today I focused on completing the evaluation phase of my machine learning models for predicting flight delays. I used classical algorithms like Decision Tree and Logistic Regression. I learned how to measure model performance using three key metrics: RMSE (Root Mean Squared Error), MAE (Mean Absolute Error), and accuracy. These helped me compare how well each model predicts delays, especially under different threshold definitions for what counts as a "delay". RMSE and MAE gave me insight into how large the prediction errors were on average, while accuracy showed how often the model predicted delay categories correctly. I also practiced generating and interpreting confusion matrices, which helped me understand the balance between false positives and false negatives.  
  
blockers: |  
  I initially struggled with interpreting RMSE and MAE values — especially understanding whether my model performance was “good enough.” After reviewing sample benchmarks and comparing between models, I realized that minimizing these values (while maintaining reasonable accuracy) gives a better overall prediction model. Another challenge was ensuring consistent results when scaling input features for different models.
  
reflection: |
  Using simpler models like Decision Trees and Logistic Regression helped me better understand the strengths and weaknesses of each algorithm. Unlike complex neural networks, these models offer greater interpretability, especially useful for explaining model decisions to stakeholders like airport managers or airline planners. Moving forward, I plan to tune the hyperparameters of my best-performing model and further reduce the prediction errors. I’m also thinking about introducing Random Forest or XGBoost next, which are known to improve performance over a single decision tree. Today reminded me that simplicity, when combined with proper evaluation, can still yield powerful insights in applied machine learning.
---

